from langchain.llms import Ollama
from langchain.chains import RetrievalQA
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
import lightgbm as lgb
import numpy as np

class MedicalAgent:
    def __init__(self, llm_model_name='llama3.2', lightgbm_models=None, documents=None):
        """
        Initializes the medical agent with an LLM, LightGBM models, and a RAG system.

        :param llm_model_name: Name of the LLM model to use.
        :param lightgbm_models: Dictionary of LightGBM models for different predictions.
        :param documents: List of documents for the RAG system.
        """
        self.llm = Ollama(model=llm_model_name)
        self.lightgbm_models = lightgbm_models if lightgbm_models else {}
        self.retriever = self._initialize_retriever(documents) if documents else None

    def _initialize_retriever(self, documents):
        """
        Initializes the document retrieval system for RAG.

        :param documents: List of documents to index.
        :return: Document retriever object.
        """
        embeddings = OpenAIEmbeddings()
        vector_store = FAISS.from_texts(documents, embeddings)
        retriever = vector_store.as_retriever()
        return retriever

    def predict_diagnosis(self, user_data, model_name):
        """
        Predicts a diagnosis based on user data using a LightGBM model.

        :param user_data: Dictionary with relevant user information.
        :param model_name: Name of the LightGBM model to use.
        :return: Predicted diagnosis.
        """
        model = self.lightgbm_models.get(model_name)
        if not model:
            raise ValueError(f"Model {model_name} not found.")
        data = np.array([user_data[key] for key in sorted(user_data.keys())]).reshape(1, -1)
        diagnosis = model.predict(data)
        return diagnosis[0]

    def explain_diagnosis(self, diagnosis):
        """
        Provides a detailed explanation of the diagnosis using the LLM.

        :param diagnosis: Diagnosis to explain.
        :return: Explanation of the diagnosis.
        """
        prompt = f"Please provide a detailed explanation of the diagnosis: {diagnosis}."
        response = self.llm.generate(prompt)
        return response

    def answer_medical_question(self, question):
        """
        Answers a medical question using the RAG system.

        :param question: User's medical question.
        :return: Response generated by the RAG system.
        """
        if not self.retriever:
            raise ValueError("Document retrieval system is not initialized.")
        qa_chain = RetrievalQA(llm=self.llm, retriever=self.retriever)
        response = qa_chain.run(question)
        return response
